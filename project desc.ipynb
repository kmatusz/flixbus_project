{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flixbus - project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My project is an advanced webscraper of flixbus.com site. The purpose is to automatically download the data about trips between cities and at times that the app user is interested in. User will be able to define parameters of the search, and get the results in a form of a csv download/display table. The scrapper part of the app will be run periodically (e.g. once a day). This gives the end user ability to analyse the trends visible in the pricing of particular trip. This way user can alos semi-automatically check whether the there is a drop in price and tickets are cheaper than usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app will consist of 3 main parts:\n",
    "\n",
    "- Web-scraping module\n",
    "- SQLite Database\n",
    "- Flask Web app"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web-scraper part:\n",
    " \n",
    "- Is run at specified times\n",
    "- Gets parameters of website searches to scrape from the database\n",
    "- After getting parameters it scrapes the pages specified, converts them to correct format and commits the scraping results to the database\n",
    "\n",
    "#### Database:\n",
    "\n",
    "Stores 4 kinds of informations:\n",
    "- Scraping results - from executed scraper jobs\n",
    "- Dictionaries for clearer presentation of scraping results to the user\n",
    "- Authentication management - user logins and passwords\n",
    "- Logs - from scraping execution, updates of parameters from the users and about users logins\n",
    "\n",
    "#### App:\n",
    "\n",
    "Has features (views):\n",
    "\n",
    "- User authentication\n",
    "- Adding new parameters for scraping (eg. trip Cracow-Warsaw on 12.01.2020)\n",
    "- Fetching the results of previously defined jobs (for each user)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/28885827/how-to-reverse-engineer-data-models-from-an-existing-database-in-python-and-sql/33379254 - zmiana na sqlalchemy z kodu sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The end user after adding the parameters to scrape will be able to get table like this:\n",
    "\n",
    "trip_date | trip_time  | city_from | city_to | price | distance | price_per_100km \n",
    "\n",
    "for each defined job. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two user stories of the app are:\n",
    "\n",
    "1. I want to travel from Warsaw to Cracow or Gdansk, departure date should be between 01.01.2020 and 03.01.2020, and return date between 20.01 and 10.02. Using standard search box this would require ~120 searches. \n",
    "2. For analytic purposes,I want to know what are the patterns in pricing of Warsaw-Cracow connection.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
